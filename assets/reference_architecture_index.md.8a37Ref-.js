import{_ as n,c as a,o as t,ag as s}from"./chunks/framework.MOZBvIbK.js";const h=JSON.parse('{"title":"Architecture","description":"","frontmatter":{},"headers":[],"relativePath":"reference/architecture/index.md","filePath":"reference/architecture/index.md","lastUpdated":1749575758000}'),o={name:"reference/architecture/index.md"};function i(r,e,p,l,c,d){return t(),a("div",null,e[0]||(e[0]=[s(`<h1 id="architecture" tabindex="-1">Architecture <a class="header-anchor" href="#architecture" aria-label="Permalink to &quot;Architecture&quot;">​</a></h1><p>Saluki is a toolkit for building observability data planes. It provides a set of building blocks for ingesting, processing, and forwarding observability data, as well as all of the related helpers for doing so in a performant, reliable, and efficient way.</p><h2 id="core-concepts" tabindex="-1">Core Concepts <a class="header-anchor" href="#core-concepts" aria-label="Permalink to &quot;Core Concepts&quot;">​</a></h2><h3 id="topologies" tabindex="-1">Topologies <a class="header-anchor" href="#topologies" aria-label="Permalink to &quot;Topologies&quot;">​</a></h3><p>In Saluki, users construct a <strong>topology</strong>, which is a collection of uniquely identified <strong>components</strong> connected together in a directed, acyclic graph. This just means that components send data to each other in a single direction, like a pipeline of Unix commands (e.g., <code>cat messages | grep error | wc -l</code>), and that there can be no cycles between components (e.g., componentA -&gt; component B -&gt; component A).</p><p>OK, so why does this matter? This structure allows components to be easily composed together, and it allow for a component to send data to multiple downstream components <em>or</em> for a component to receive data from multiple upstream components.</p><p>Topologies are required to have an input component and an output component, as we need a way for data to enter the topology as well as leave it. This means a topology needs to have <em>at least</em> two components, but could have arbitrarily more. Connections between components are manually specified using the unique identifiers, such as declaring a connection between &quot;A&quot; and &quot;B&quot;, where &quot;A&quot; and &quot;B&quot; are both the names of components in the topology.</p><p>Below is an visual example of a simple topology -- source, transform, and destination -- as well as an example of a more complex topology with multiple sources, transforms, and destinations:</p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Simple:                                                           </span></span>
<span class="line"><span>┌─────────────┐        ┌───────────────┐       ┌─────────────────┐</span></span>
<span class="line"><span>│  DogStatsD  ├────────▶   Aggregate   ├───────▶   DD Metrics    │</span></span>
<span class="line"><span>│  (source)   │        │  (transform)  │       │  (destination)  │</span></span>
<span class="line"><span>└─────────────┘        └───────────────┘       └─────────────────┘</span></span>
<span class="line"><span>                                                                  </span></span>
<span class="line"><span>Slightly complex:                                                 </span></span>
<span class="line"><span>┌────────────────────┐        ┌───────────────┐                   </span></span>
<span class="line"><span>│  Internal Metrics  ├────────▶   Aggregate   ├──────────┐       </span></span>
<span class="line"><span>│      (source)      │        │  (transform)  │          │       </span></span>
<span class="line"><span>└────────────────────┘        └───────────────┘          │       </span></span>
<span class="line"><span>                                                         │       </span></span>
<span class="line"><span>                                                         │       </span></span>
<span class="line"><span>┌─────────────────┐      ┌───────────────┐     ┌─────────▼───────┐</span></span>
<span class="line"><span>│  OpenTelemetry  ├──────▶   Aggregate   ├─────▶    DD Metrics   │</span></span>
<span class="line"><span>│    (source)     │      │  (transform)  │     │  (destination)  │</span></span>
<span class="line"><span>└─────┬──────┬────┘      └───────────────┘     └─────────────────┘</span></span>
<span class="line"><span>      │      │       ▲                                           ▲</span></span>
<span class="line"><span>	  │      │       └────────────────── metrics ────────────────┘</span></span>
<span class="line"><span>      │      │                                                     </span></span>
<span class="line"><span>      │      │          ┌───────────────┐      ┌─────────────────┐</span></span>
<span class="line"><span>      │      └──────────▶    Redact     ├──────▶     DD Logs     │</span></span>
<span class="line"><span>      │                 │  (transform)  │      │  (destination)  │</span></span>
<span class="line"><span>      │                 └───────────────┘      └─────────────────┘</span></span>
<span class="line"><span>      │      ▲                                                   ▲</span></span>
<span class="line"><span>	  │      └────────────────────── logs ───────────────────────┘</span></span>
<span class="line"><span>      │                                                            </span></span>
<span class="line"><span>	  |      ┌───────────────────── traces ──────────────────────┐</span></span>
<span class="line"><span>	  |      ▼                                                   ▼</span></span>
<span class="line"><span>      │                                        ┌─────────────────┐</span></span>
<span class="line"><span>      └────────────────────────────────────────▶    DD Traces    │</span></span>
<span class="line"><span>                                               │  (destination)  │</span></span>
<span class="line"><span>                                               └─────────────────┘</span></span></code></pre></div><h3 id="components" tabindex="-1">Components <a class="header-anchor" href="#components" aria-label="Permalink to &quot;Components&quot;">​</a></h3><p>Components are the discrete chunks of functionality that make up a topology, and are grouped into three categories: <strong>sources</strong>, <strong>transforms</strong>, and <strong>destinations</strong>. All components interact with each other over channels, which are the primary mechanism for sending data from one component to another.</p><p>Components implement specific traits (an <code>interface</code> in Go) in order to indicate what type of component they are, and these traits also requiring describing the input and/or output data types they support, which is used by the topology graph to ensure that components are connected correctly.</p><h4 id="sources" tabindex="-1">Sources <a class="header-anchor" href="#sources" aria-label="Permalink to &quot;Sources&quot;">​</a></h4><p>Sources are the group of components used to get data into a topology.</p><p>There are no real limitations on how to get data in, but generally speaking, most sources are either <em>push-</em> or <em>pull-based</em>, where data is either <em>pushed</em> in, such as by a client, or <em>pulled</em> in, such as by querying an external service. In some cases, a source might be able to generate its own data.</p><p>Examples of sources (some of which do not currently exist):</p><ul><li>DogStatsD (receive metrics from StatsD/DogStatsD clients)</li><li>File (pull data from files on disk)</li><li>Internal metrics (capture internal telemetry generated by Saluki)</li></ul><h4 id="transforms" tabindex="-1">Transforms <a class="header-anchor" href="#transforms" aria-label="Permalink to &quot;Transforms&quot;">​</a></h4><p>Transforms are the group of components used to process data within a topology.</p><p>Broadly speaking, transforms are used to either combine data (e.g., aggregation), modify data (e.g., enrichment, conversion) or filter data (e.g., dropping, sampling). Transforms are always in the &quot;middle&quot; of a topology, as they don&#39;t generate data themselves.</p><p>Examples of transforms (some of which do not currently exist):</p><ul><li>Aggregate (aggregate metrics over a time window, based on their name/tags)</li><li>Origin Enrichment (enrich metrics with additional tags based on their point of origin)</li><li>Sampling (deterministically allow a certain percentage of events to pass through, dropping the rest)</li><li>Router (route events to different outputs based on configurable logic)</li></ul><h4 id="destinations" tabindex="-1">Destinations <a class="header-anchor" href="#destinations" aria-label="Permalink to &quot;Destinations&quot;">​</a></h4><p>Destinations are the group of components used to send data out of a topology.</p><p>Like sources, there are no real limitations on how to get data out, and most destinations will either be push or pull, but the majority of destinations will be push-based, where data is pushed to an external system.</p><p>Examples of destinations (some of which do not currently exist):</p><ul><li>Datadog Metrics (send metrics to the Datadog platform)</li><li>Prometheus Scrape (expose a Prometheus-compatible scrape endpoint for metrics)</li><li>OpenTelemetry (send logs, metrics, and traces to an OpenTelemetry receiver)</li></ul><h3 id="events" tabindex="-1">Events <a class="header-anchor" href="#events" aria-label="Permalink to &quot;Events&quot;">​</a></h3><p>In order to facilitate communication between components in a generic way, Saluki uses a unified data model based on a single enum type, <code>Event</code>. Events represent all possible data types that Saluki is able to handle, such as metrics (currently supported), logs and traces (not yet supported), and so on.</p><p>Naturally, not every component will emit all event types, and not every component will be able to handle all event types. This is dealt with by the logic mentioned prior, where connected components must have a compatible set of input/output data types. For example, if component A and component B are connected together, and A only emits metrics while B only accepts logs, the topology would throw an error during validation.</p><p>On the component side, components will do a minimal amount of runtime checking / destructing to unwrap <code>Event</code>s and access the true event, such as the actual <code>Metric</code> container within.</p><h3 id="outputs" tabindex="-1">Outputs <a class="header-anchor" href="#outputs" aria-label="Permalink to &quot;Outputs&quot;">​</a></h3><p>Source and transform components can emit their data in one of two ways: using a default output, or a <strong>named</strong> output.</p><p>Default outputs are exactly what they sound like, and are used as the primary output of a component. This is the pattern used when a component only emits a single event type, and has no specialization otherwise.</p><p>For some components, however, they may emit multiple event types, or they may dynamically emit certain events/event types based on their configuration. In order to support this, Saluki has a concept of &quot;named&quot; outputs, where a component can have a dynamic number of outputs, each with a qualified name.</p><p>The type of output used influences how the component connections are declared, where connecting to the default output of a component is achieved by specifying just the unique identifier of the upstream component, but connecting to a named output uses a compound identifier, based on the component&#39;s unique identifier and the name of the output.</p><p>For example, a hypothetical OpenTelemetry source could receive logs, metrics, or traces from clients. It would be inefficient to have a default output that emitted all three event types, since all connected downstream components would have to be able to handle all of those event types, even if it just meant forwarding the ones they didn&#39;t care about. Instead, named outputs could be used to send metrics, logs, and traces each on their own dedicated outputs. This would allow downstream components to connect only to the named output that had the event type they cared about, such as first sending the metrics to an aggregate transform while sending logs and traces directly to an OpenTelemetry destination.</p><p>Another example would be a hypothetical router transform used to route log events based on their severity. There could be a route for low-priority logs and one for high-priority logs, where each route would create a specific named output on the transform. The topology could then be configured to connect the low-priority output to a destination that perhaps batches logs more aggressively, and results in less frequent writes, while the high-priority output could be connected to a destination that prioritizes real-time ingestion.</p><p>Below is an example of the available outputs of two different components, where one component has only a default output, and the other has multiple named outputs:</p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>┌──────────────────────────┐                                                            </span></span>
<span class="line"><span>│                          │                                                            </span></span>
<span class="line"><span>│    DogStatsD (source)    │           default metrics output (output ID: &quot;dsd&quot;)        </span></span>
<span class="line"><span>│                          ├───────────────────────────────────────────────────────────▶</span></span>
<span class="line"><span>│   Component ID: &quot;dsd&quot;    │                                                            </span></span>
<span class="line"><span>│                          │                                                            </span></span>
<span class="line"><span>└──────────────────────────┘                                                            </span></span>
<span class="line"><span>                                                                                        </span></span>
<span class="line"><span>                                       named metrics output (output ID: &quot;otel.metrics&quot;) </span></span>
<span class="line"><span>                                    ┌──────────────────────────────────────────────────▶</span></span>
<span class="line"><span>┌──────────────────────────┐        │                                                   </span></span>
<span class="line"><span>│                          ├────────┘                                                   </span></span>
<span class="line"><span>│  OpenTelemetry (source)  │           named logs output (output ID: &quot;otel.logs&quot;)       </span></span>
<span class="line"><span>│                          ├───────────────────────────────────────────────────────────▶</span></span>
<span class="line"><span>│   Component ID: &quot;otel&quot;   │                                                            </span></span>
<span class="line"><span>│                          ├────────┐                                                   </span></span>
<span class="line"><span>└──────────────────────────┘        │  named traces output (output ID: &quot;otel.traces&quot;)   </span></span>
<span class="line"><span>                                    └──────────────────────────────────────────────────▶</span></span></code></pre></div><h3 id="shutdown" tabindex="-1">Shutdown <a class="header-anchor" href="#shutdown" aria-label="Permalink to &quot;Shutdown&quot;">​</a></h3><p>Topologies provide ordered shutdown through two mechanisms: the used of a shutdown coordinator, and the implicit behavior of the channels used to connect components together.</p><p>Shutdown starts at the top level, controlled by the topology itself. A signal is sent to all sources indicating that shutdown should proceed. Sources will then begin to shutdown, stopping new data/connections/etc from coming in, as well as waiting for existing work to complete. Once a source shuts down, it signals back to the topology that it is done. Once all sources have signaled that they have shut down, the topology waits for all remaining components to complete as well.</p><p>However, transforms and destinations are not signaled directly to shutdown. Instead, they depend on the implicit behavior of the channels that are used for receiving events. Once these channels have been drained of any remaining events, and all of the senders have shutdown, the channel will be marked as closed. This lets transforms and destination focus on simply receiving from the channel until it is closed, at which point they will naturally complete and shutdown.</p><p>By triggering shutdown at the source level, and then having each subsequent component process any remaining events, we ensure that all remaining events are processed before the topology is completely shutdown.</p><h3 id="runtime" tabindex="-1">Runtime <a class="header-anchor" href="#runtime" aria-label="Permalink to &quot;Runtime&quot;">​</a></h3><p>Constructing a topology is split into two phases of <em>building</em> and <em>spawning</em>, which ensures that we can validate that each component in the topology as being both configured and connected correctly, and then finally spawn the topology to begin accepting, processing, and forwarding data.</p><p>When a topology is spawned, we do so by using an asynchronous runtime, where each component is treated as an individual &quot;task,&quot; and individual components can spawn their own tasks. Saluki uses <a href="https://docs.rs/tokio" target="_blank" rel="noreferrer">Tokio</a> as the underlying runtime implementation, as it provides a high-performance, work-stealing runtime that is well-suited for running data-intensive pipelines such as the ones built with Saluki.</p><h4 id="concurrency-and-parallelism" tabindex="-1">Concurrency and parallelism <a class="header-anchor" href="#concurrency-and-parallelism" aria-label="Permalink to &quot;Concurrency and parallelism&quot;">​</a></h4><p>Asynchronous runtimes in Rust are based on &quot;futures&quot;, which models computation that depends on external resources (I/O, timers, messages, etc) which may become ready at an arbitrary point in time in the <em>future</em>. We spawn these futures as <em>tasks</em>. If you&#39;re familiar with JavaScript&#39;s <em>promises</em>, or Go&#39;s <em>goroutines</em>, you can think of futures as a similar concept. These tasks are scheduled across multiple operating system threads, and are able to run concurrently, and potentially in parallel, allowing for a smaller number of OS threads to effectively (and resource efficiently) run many tasks.</p><h4 id="task-isolation" tabindex="-1">Task isolation <a class="header-anchor" href="#task-isolation" aria-label="Permalink to &quot;Task isolation&quot;">​</a></h4><p>Tasks also provide a natural level of isolation between each other, and so are useful for splitting up independent workloads, such as spawning a separate task for each client connection or for each log file being read.</p><p>In fact, splitting computation into more granular tasks is ideal, as it helps to allow for better balancing the work across the runtime&#39;s worker threads. As Tokio is a work-stealing runtime, idle worker threads can &quot;steal&quot; tasks from other worker threads when they are busy or blocked.</p>`,53)]))}const m=n(o,[["render",i]]);export{h as __pageData,m as default};
