use std::{num::NonZeroUsize, sync::Arc};

use memory_accounting::{MemoryBounds, MemoryBoundsBuilder};
use saluki_common::collections::{FastConcurrentHashMap, FastConcurrentHashSet};
use saluki_context::{
    origin::OriginTagCardinality,
    tags::{SharedTagSet, TagSet, TagVisitor},
};
use tracing::{debug, trace};

use crate::workload::{
    aggregator::MetadataStore,
    entity::EntityId,
    metadata::{MetadataAction, MetadataOperation},
};

#[derive(Clone, Default)]
struct TagStorage {
    low_cardinality: Arc<FastConcurrentHashMap<EntityId, SharedTagSet>>,
    orchestrator_cardinality: Arc<FastConcurrentHashMap<EntityId, SharedTagSet>>,
    high_cardinality: Arc<FastConcurrentHashMap<EntityId, SharedTagSet>>,
}

impl TagStorage {
    fn set_entity_tags(&self, entity_id: EntityId, tags: TagSet, cardinality: OriginTagCardinality) {
        match cardinality {
            OriginTagCardinality::None => return,
            OriginTagCardinality::Low => self.low_cardinality.pin().insert(entity_id, tags.into_shared()),
            OriginTagCardinality::Orchestrator => self
                .orchestrator_cardinality
                .pin()
                .insert(entity_id, tags.into_shared()),
            OriginTagCardinality::High => self.high_cardinality.pin().insert(entity_id, tags.into_shared()),
        };
    }

    fn delete_entity(&self, entity_id: &EntityId) {
        self.low_cardinality.pin().remove(entity_id);
        self.orchestrator_cardinality.pin().remove(entity_id);
        self.high_cardinality.pin().remove(entity_id);
    }

    fn get_entity_tags(&self, entity_id: &EntityId, cardinality: OriginTagCardinality) -> Option<SharedTagSet> {
        match cardinality {
            OriginTagCardinality::None => None,
            OriginTagCardinality::Low => self.low_cardinality.pin().get(entity_id).cloned(),
            OriginTagCardinality::Orchestrator => self.orchestrator_cardinality.pin().get(entity_id).cloned(),
            OriginTagCardinality::High => self.high_cardinality.pin().get(entity_id).cloned(),
        }
    }
}

/// A unified tag store for entities.
///
/// Entities will, in general, have a number of specific tags associated with them. [`TagStore`] is a store for these
/// entity tag mappings, and is designed to be driven by metadata operations generated by various metadata collectors.
/// It provides a low-overhead, thread-safe handle to query the tags for a given entity.
pub struct TagStore {
    entity_limit: NonZeroUsize,
    active_entities: Arc<FastConcurrentHashSet<EntityId>>,
    entity_aliases: Arc<FastConcurrentHashMap<EntityId, EntityId>>,
    entity_tags: TagStorage,
}

impl TagStore {
    /// Creates a new `TagStore` with the given entity limit.
    ///
    /// The entity limit is the maximum number of unique entities that can be stored. Once the limit is reached, new
    /// entities will not be added to the store.
    pub fn with_entity_limit(entity_limit: NonZeroUsize) -> Self {
        Self {
            entity_limit,
            active_entities: Arc::new(FastConcurrentHashSet::default()),
            entity_aliases: Arc::new(FastConcurrentHashMap::default()),
            entity_tags: TagStorage::default(),
        }
    }

    /// Returns the maximum number of unique entities that can be tracked by the store at any given time.
    pub fn entity_limit(&self) -> usize {
        self.entity_limit.get()
    }

    fn track_entity(&mut self, entity_id: &EntityId) -> bool {
        let guard = self.active_entities.guard();

        if self.active_entities.contains(entity_id, &guard) {
            return true;
        }

        if self.active_entities.len() >= self.entity_limit() {
            return false;
        }

        let _ = self.active_entities.insert(entity_id.clone(), &guard);
        true
    }

    fn delete_entity(&mut self, entity_id: &EntityId) {
        self.active_entities.pin().remove(entity_id);

        // Delete all of the tags for the entity, and any alias mapping that may exist.
        self.entity_tags.delete_entity(entity_id);
        self.entity_aliases.pin().remove(entity_id);
    }

    fn set_entity_tags(&mut self, entity_id: EntityId, tags: TagSet, cardinality: OriginTagCardinality) {
        if !self.track_entity(&entity_id) {
            trace!(
                entity_limit = self.entity_limit(),
                %entity_id,
                "Entity limit reached, not setting tags for entity."
            );
            return;
        }

        self.entity_tags.set_entity_tags(entity_id, tags, cardinality);
    }

    fn add_entity_alias(&mut self, source_entity_id: EntityId, target_entity_id: EntityId) {
        let _ = self.entity_aliases.pin().insert(source_entity_id, target_entity_id);
    }

    /// Returns a `TagStoreQuerier` that can be used to concurrently query the tag store.
    pub fn querier(&self) -> TagStoreQuerier {
        TagStoreQuerier {
            entity_tags: self.entity_tags.clone(),
            entities: Arc::clone(&self.active_entities),
            aliases: Arc::clone(&self.entity_aliases),
        }
    }
}

impl MetadataStore for TagStore {
    fn name(&self) -> &'static str {
        "tag_store"
    }

    fn process_operation(&mut self, operation: MetadataOperation) {
        debug!(?operation, "Processing metadata operation.");

        // TODO: Maybe come up with a better pattern for doing "only clone for the first N-1 actions, don't clone for the
        // Nth" since we're needlessly cloning a lot with this current approach.
        let entity_id = operation.entity_id;
        for action in operation.actions {
            match action {
                MetadataAction::Delete => self.delete_entity(&entity_id.clone()),
                MetadataAction::AddAlias { target_entity_id } => {
                    self.add_entity_alias(entity_id.clone(), target_entity_id)
                }
                MetadataAction::SetTags { cardinality, tags } => {
                    self.set_entity_tags(entity_id.clone(), tags, cardinality)
                }
                // We don't care about External Data.
                MetadataAction::AttachExternalData { .. } => {}
            }
        }
    }
}

impl MemoryBounds for TagStore {
    fn specify_bounds(&self, builder: &mut MemoryBoundsBuilder) {
        // TODO: We don't properly consider the hierarchy mappings here.
        //
        // The problem with entity hierarchy mappings is that they're essentially unbounded. Since we don't require
        // actually having tags present for a linked ancestor, you could just have however many ancestry links as you
        // want, and thus the unbounded aspect.
        //
        // Conceptually, every ancestry link ought to represent two entities that both have tags, otherwise it's kind of
        // useless to link them... but I'll need to think about how we scope down the flexibility so that we can
        // calculate a proper bound.
        //
        // For now, we'll use a reasonable guess of 1x the entity limit: since we generally only link container PIDs to
        // container IDs, we would expect to have no more links than entities with tags, and thus 1x the entity limit.

        builder
            .firm()
            // Active entities.
            .with_array::<EntityId>("entity ids", self.entity_limit())
            // Entity hierarchy mappings.
            //
            // See TODO note about why this is an estimate.
            .with_map::<EntityId, EntityId>("entity id map", self.entity_limit())
            // Low cardinality entity tags.
            .with_map::<EntityId, TagSet>("low cardinality entity tagset map", self.entity_limit())
            // Orchestrator cardinality entity tags.
            .with_map::<EntityId, TagSet>("orchestrator cardinality entity tagset map", self.entity_limit())
            // High cardinality entity tags.
            .with_map::<EntityId, TagSet>("high cardinality entity tagset map", self.entity_limit());
    }
}

/// A handle for querying entity tags from a `TagStore`.
#[derive(Clone)]
pub struct TagStoreQuerier {
    entity_tags: TagStorage,
    entities: Arc<FastConcurrentHashSet<EntityId>>,
    aliases: Arc<FastConcurrentHashMap<EntityId, EntityId>>,
}

impl TagStoreQuerier {
    /// Visits all tags for an entity at the requested cardinality and below.
    ///
    /// This means that tags from the requested cardinality, and all lower precedence cardinality levels, will be
    /// visited. The cardinality levels, in order of precedence (lowest to highest), are:
    ///
    /// - low cardinality
    /// - orchestrator cardinality
    /// - high cardinality
    ///
    /// When an entity is aliased, the tags for the aliased entity will be visited instead of any tags for the entity itself.
    ///
    /// Returns `false` if the entity does not exist at all (no alias, no tags), `true` otherwise.
    pub fn visit_entity_tags(
        &self, entity_id: &EntityId, cardinality: OriginTagCardinality, tag_visitor: &mut dyn TagVisitor,
    ) -> bool {
        const CARDINALITY_LEVELS: [OriginTagCardinality; 3] = [
            OriginTagCardinality::Low,
            OriginTagCardinality::Orchestrator,
            OriginTagCardinality::High,
        ];

        let mut entity_exists = false;

        // If an entity is aliased, use that entity's tags instead of the entity's tags.
        let aliases = self.aliases.pin();
        let entity_id = match aliases.get(entity_id) {
            Some(alias) => {
                // If an alias exists, then the original entity also "exists".
                entity_exists = true;
                trace!(?alias, ?entity_id, "Entity is aliased.");

                alias
            }
            None => entity_id,
        };

        for current_cardinality in CARDINALITY_LEVELS.iter() {
            if let Some(tags) = self.entity_tags.get_entity_tags(entity_id, *current_cardinality) {
                trace!(
                    tags_len = tags.len(),
                    ?entity_id,
                    cardinality = current_cardinality.as_str(),
                    "Visiting tags for entity."
                );
                entity_exists = true;

                for tag in &tags {
                    tag_visitor.visit_tag(tag);
                }
            }

            // If we've reached the target cardinality, stop visiting tags.
            if *current_cardinality == cardinality {
                break;
            }
        }

        entity_exists
    }

    /// Gets the exact tags for an entity at the specific cardinality.
    ///
    /// Unlike `visit_entity_tags`, this method does not visit tags at lower cardinalities, and it does not visit tags
    /// for an aliased entity.
    ///
    /// If no tags can be found for the entity, or at the given cardinality, `None` is returned.
    pub fn get_exact_entity_tags(
        &self, entity_id: &EntityId, cardinality: OriginTagCardinality,
    ) -> Option<SharedTagSet> {
        self.entity_tags.get_entity_tags(entity_id, cardinality)
    }

    /// Visits each active entity in the tag store.
    pub fn visit_active_entities<F>(&self, mut visitor: F)
    where
        F: FnMut(&EntityId),
    {
        for entity_id in self.entities.pin().iter() {
            visitor(entity_id);
        }
    }

    /// Visits each entity alias in the tag store.
    pub fn visit_entity_aliases<F>(&self, mut visitor: F)
    where
        F: FnMut(&EntityId, &EntityId),
    {
        for (entity_id, target_entity_id) in self.aliases.pin().iter() {
            visitor(entity_id, target_entity_id);
        }
    }
}

// NOTE: All of the unit tests that deal with merging the "expected tags" by using `Extend` are designed/ordered to
// avoid creating tags with multiple values, since the logic for `TagSet` doesn't replace existing tags, but simply
// aggregates the values of existing tags.
#[cfg(test)]
mod tests {
    use std::num::NonZeroUsize;

    use saluki_context::tags::{Tag, TagSet};
    use stringtheory::MetaString;

    use super::*;
    use crate::workload::helpers::OneOrMany;

    const DEFAULT_ENTITY_LIMIT: NonZeroUsize = unsafe { NonZeroUsize::new_unchecked(10) };

    macro_rules! low_cardinality {
        ($entity_id:expr, tags => [$($key:literal => $value:literal),+]) => {{
            tag_values!($entity_id, OriginTagCardinality::Low, tags => [$($key => $value,)+])
        }};
    }

    macro_rules! orch_cardinality {
        ($entity_id:expr, tags => [$($key:literal => $value:literal),+]) => {{
            tag_values!($entity_id, OriginTagCardinality::Orchestrator, tags => [$($key => $value,)+])
        }};
    }

    macro_rules! high_cardinality {
        ($entity_id:expr, tags => [$($key:literal => $value:literal),+]) => {{
            tag_values!($entity_id, OriginTagCardinality::High, tags => [$($key => $value,)+])
        }};
    }

    macro_rules! tag_values {
        ($entity_id:expr, $cardinality:expr, tags => [$($key:literal => $value:literal),+ $(,)?]) => {{
            let mut expected_tags = TagSet::default();
            let mut tags_to_set = TagSet::default();

            $(
                let tag = format!("{}:{}", $key, $value);
                expected_tags.insert_tag(tag.clone());
                tags_to_set.insert_tag(tag);
            )+

            let operations = vec![
                MetadataOperation {
                    entity_id: $entity_id.clone(),
                    actions: OneOrMany::One(MetadataAction::SetTags {
                        cardinality: $cardinality,
                        tags: tags_to_set,
                    }),
                }
            ];

            (expected_tags, operations)
        }};
    }

    fn visit_tags(querier: &TagStoreQuerier, entity_id: &EntityId, cardinality: OriginTagCardinality) -> TagSet {
        let mut tags = TagSet::default();
        querier.visit_entity_tags(entity_id, cardinality, &mut |tag: &Tag| {
            tags.insert_tag(tag.clone());
        });
        tags
    }

    fn sorted_ts(tags: TagSet) -> Vec<MetaString> {
        let mut tags = tags.into_iter().map(|t| t.into_inner()).collect::<Vec<_>>();
        tags.sort();
        tags
    }

    #[test]
    fn basic() {
        let entity_id_one = EntityId::Container("container-id-one".into());
        let entity_id_two = EntityId::Container("container-id-two".into());
        let entity_id_three = EntityId::Container("container-id-three".into());
        let (low_expected_tags, low_operations) = low_cardinality!(&entity_id_one, tags => ["service" => "foo"]);
        let (orch_expected_tags, orch_operations) =
            orch_cardinality!(&entity_id_two, tags => ["kube_cluster_name" => "saluki"]);
        let (high_expected_tags, high_operations) =
            high_cardinality!(&entity_id_three, tags => ["kube_pod_name" => "foo-8xl-ah2z7"]);

        let mut store = TagStore::with_entity_limit(DEFAULT_ENTITY_LIMIT);
        for operation in low_operations.into_iter().chain(orch_operations).chain(high_operations) {
            store.process_operation(operation);
        }

        let querier = store.querier();

        let low_actual_tags = visit_tags(&querier, &entity_id_one, OriginTagCardinality::Low);
        assert_eq!(low_actual_tags, low_expected_tags);

        let orch_actual_tags = visit_tags(&querier, &entity_id_two, OriginTagCardinality::Orchestrator);
        assert_eq!(orch_actual_tags, orch_expected_tags);

        let high_actual_tags = visit_tags(&querier, &entity_id_three, OriginTagCardinality::High);
        assert_eq!(high_actual_tags, high_expected_tags);
    }

    #[test]
    fn delete_entity() {
        let entity_id = EntityId::Container("container-id".into());
        let (expected_tags, operations) = low_cardinality!(&entity_id, tags => ["service" => "foo"]);

        let mut store = TagStore::with_entity_limit(DEFAULT_ENTITY_LIMIT);
        for operation in operations {
            store.process_operation(operation);
        }

        let querier = store.querier();

        // We should have tags for the entity.
        let actual_tags = visit_tags(&querier, &entity_id, OriginTagCardinality::Low);
        assert_eq!(sorted_ts(actual_tags), sorted_ts(expected_tags));

        // Now delete the entity and check that we no longer have tags for it.
        store.process_operation(MetadataOperation::delete(entity_id.clone()));

        let actual_tags = visit_tags(&querier, &entity_id, OriginTagCardinality::Low);
        assert!(actual_tags.is_empty());
    }

    #[test]
    fn obeys_entity_limit() {
        // We create three entities that we'll try to process with an entity limit of two.
        let pod_entity_id = EntityId::PodUid("datadog-agent-pod-uid".into());
        let (_, pod_operations) = low_cardinality!(&pod_entity_id, tags => ["kube_pod_name" => "datadog-agent-z1ha3"]);

        let container1_entity_id = EntityId::Container("process-agent-container-id".into());
        let (_, container1_operations) = low_cardinality!(&container1_entity_id, tags => ["service" => "foo"]);

        let container2_entity_id = EntityId::Container("trace-agent-container-id".into());
        let (_, container2_operations) = low_cardinality!(&container2_entity_id, tags => ["service" => "foo"]);

        let entity_limit = NonZeroUsize::new(2).unwrap();
        let mut store = TagStore::with_entity_limit(entity_limit);
        for operation in pod_operations {
            store.process_operation(operation);
        }
        for operation in container1_operations {
            store.process_operation(operation);
        }
        for operation in container2_operations.clone() {
            store.process_operation(operation);
        }

        // At this point, we should have tags for the pod, and container #1, but not container #2.
        let querier = store.querier();

        let pod_entity_tags = visit_tags(&querier, &pod_entity_id, OriginTagCardinality::Low);
        let container1_entity_tags = visit_tags(&querier, &container1_entity_id, OriginTagCardinality::Low);
        let container2_entity_tags = visit_tags(&querier, &container2_entity_id, OriginTagCardinality::Low);

        assert!(!pod_entity_tags.is_empty());
        assert!(!container1_entity_tags.is_empty());
        assert!(container2_entity_tags.is_empty());

        // If we delete container #1, and then process the container #2 operations again, we should then have tags for
        // container #2 but not container #1.
        store.process_operation(MetadataOperation::delete(container1_entity_id.clone()));

        for operation in container2_operations {
            store.process_operation(operation);
        }

        let pod_entity_tags = visit_tags(&querier, &pod_entity_id, OriginTagCardinality::Low);
        let container1_entity_tags = visit_tags(&querier, &container1_entity_id, OriginTagCardinality::Low);
        let container2_entity_tags = visit_tags(&querier, &container2_entity_id, OriginTagCardinality::Low);

        assert!(!pod_entity_tags.is_empty());
        assert!(container1_entity_tags.is_empty());
        assert!(!container2_entity_tags.is_empty());
    }

    #[test]
    fn hierarchical_cardinality() {
        // We want to ensure that when querying for tags at a specific cardinality, we get the tags for the lower-level
        // cardinalities.
        //
        // Specifically, this means the querying for "low" cardinality tags only ever returns "low" cardinality tags,
        // querying for "orchestrator" cardinality tags returns both "low" and "orchestrator" cardinality tags, and
        // querying for "high" cardinality tags returns all three cardinalities.
        let entity_id = EntityId::Container("container-id".into());
        let (low_only_expected_tags, low_operations) = low_cardinality!(&entity_id, tags => ["service" => "foo"]);
        let (orch_only_expected_tags, orch_operations) =
            orch_cardinality!(&entity_id, tags => ["kube_cluster_name" => "saluki"]);
        let (high_only_expected_tags, high_operations) =
            high_cardinality!(&entity_id, tags => ["container_name" => "foo-8xl-ah2z7"]);

        let mut store = TagStore::with_entity_limit(DEFAULT_ENTITY_LIMIT);
        for operation in low_operations.into_iter().chain(orch_operations).chain(high_operations) {
            store.process_operation(operation);
        }

        let low_expected_tags = low_only_expected_tags.clone();

        let mut orch_expected_tags = orch_only_expected_tags.clone();
        orch_expected_tags.extend(low_only_expected_tags.clone());

        let mut high_expected_tags = high_only_expected_tags.clone();
        high_expected_tags.extend(orch_only_expected_tags.clone());
        high_expected_tags.extend(low_only_expected_tags.clone());

        let querier = store.querier();

        let low_actual_tags = visit_tags(&querier, &entity_id, OriginTagCardinality::Low);
        assert_eq!(sorted_ts(low_actual_tags), sorted_ts(low_expected_tags));

        let orch_actual_tags = visit_tags(&querier, &entity_id, OriginTagCardinality::Orchestrator);
        assert_eq!(sorted_ts(orch_actual_tags), sorted_ts(orch_expected_tags));

        let high_actual_tags = visit_tags(&querier, &entity_id, OriginTagCardinality::High);
        assert_eq!(sorted_ts(high_actual_tags), sorted_ts(high_expected_tags));
    }
}
